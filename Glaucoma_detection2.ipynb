{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVQtgkaQd35i",
        "outputId": "a838d523-151c-42dd-fa48-74b13f229c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Training Transformer...\n",
            "Epoch 1/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m639s\u001b[0m 3s/step - accuracy: 0.5048 - loss: 0.6949 - val_accuracy: 0.5310 - val_loss: 0.7171\n",
            "Epoch 2/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m674s\u001b[0m 3s/step - accuracy: 0.6887 - loss: 0.5794 - val_accuracy: 0.7760 - val_loss: 0.4592\n",
            "Epoch 3/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 3s/step - accuracy: 0.8090 - loss: 0.4233 - val_accuracy: 0.7770 - val_loss: 0.4479\n",
            "Epoch 4/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m687s\u001b[0m 3s/step - accuracy: 0.8426 - loss: 0.3607 - val_accuracy: 0.7650 - val_loss: 0.5163\n",
            "Epoch 5/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 3s/step - accuracy: 0.8712 - loss: 0.2941 - val_accuracy: 0.7870 - val_loss: 0.5169\n",
            "Epoch 6/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m679s\u001b[0m 3s/step - accuracy: 0.8893 - loss: 0.2534 - val_accuracy: 0.7750 - val_loss: 0.6236\n",
            "Epoch 7/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 3s/step - accuracy: 0.9165 - loss: 0.1904 - val_accuracy: 0.7660 - val_loss: 0.7040\n",
            "Epoch 8/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 3s/step - accuracy: 0.9242 - loss: 0.1587 - val_accuracy: 0.7570 - val_loss: 0.9675\n",
            "Epoch 9/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m691s\u001b[0m 3s/step - accuracy: 0.9354 - loss: 0.1345 - val_accuracy: 0.7540 - val_loss: 1.2062\n",
            "Epoch 10/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m671s\u001b[0m 3s/step - accuracy: 0.9417 - loss: 0.1194 - val_accuracy: 0.7470 - val_loss: 1.6651\n",
            "Epoch 11/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m685s\u001b[0m 3s/step - accuracy: 0.9545 - loss: 0.1026 - val_accuracy: 0.7580 - val_loss: 1.6980\n",
            "Epoch 12/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 3s/step - accuracy: 0.9644 - loss: 0.0779 - val_accuracy: 0.7400 - val_loss: 1.9177\n",
            "Epoch 13/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 3s/step - accuracy: 0.9678 - loss: 0.0739 - val_accuracy: 0.7470 - val_loss: 1.9187\n",
            "Epoch 14/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 3s/step - accuracy: 0.9710 - loss: 0.0656 - val_accuracy: 0.7490 - val_loss: 2.4103\n",
            "Epoch 15/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m684s\u001b[0m 3s/step - accuracy: 0.9700 - loss: 0.0719 - val_accuracy: 0.7470 - val_loss: 2.4119\n",
            "Epoch 16/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 3s/step - accuracy: 0.9804 - loss: 0.0491 - val_accuracy: 0.7410 - val_loss: 2.4470\n",
            "Epoch 17/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m628s\u001b[0m 3s/step - accuracy: 0.9787 - loss: 0.0429 - val_accuracy: 0.7530 - val_loss: 2.5771\n",
            "Epoch 18/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m671s\u001b[0m 3s/step - accuracy: 0.9838 - loss: 0.0444 - val_accuracy: 0.7520 - val_loss: 1.8202\n",
            "Epoch 19/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 3s/step - accuracy: 0.9202 - loss: 0.2661 - val_accuracy: 0.7480 - val_loss: 0.9612\n",
            "Epoch 20/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 3s/step - accuracy: 0.9324 - loss: 0.1706 - val_accuracy: 0.7350 - val_loss: 1.0641\n",
            "Epoch 21/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 3s/step - accuracy: 0.9501 - loss: 0.1063 - val_accuracy: 0.7420 - val_loss: 1.9028\n",
            "Epoch 22/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 3s/step - accuracy: 0.9773 - loss: 0.0565 - val_accuracy: 0.7240 - val_loss: 2.2312\n",
            "Epoch 23/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 3s/step - accuracy: 0.9722 - loss: 0.0610 - val_accuracy: 0.7520 - val_loss: 2.0406\n",
            "Epoch 24/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 3s/step - accuracy: 0.9801 - loss: 0.0434 - val_accuracy: 0.7160 - val_loss: 2.7116\n",
            "Epoch 25/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 3s/step - accuracy: 0.9827 - loss: 0.0343 - val_accuracy: 0.7470 - val_loss: 3.1727\n",
            "Epoch 26/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 3s/step - accuracy: 0.9841 - loss: 0.0345 - val_accuracy: 0.7170 - val_loss: 1.2043\n",
            "Epoch 27/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m628s\u001b[0m 3s/step - accuracy: 0.9784 - loss: 0.0543 - val_accuracy: 0.7170 - val_loss: 2.2816\n",
            "Epoch 28/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m671s\u001b[0m 3s/step - accuracy: 0.9851 - loss: 0.0366 - val_accuracy: 0.7350 - val_loss: 2.8262\n",
            "Epoch 29/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 3s/step - accuracy: 0.9906 - loss: 0.0240 - val_accuracy: 0.7480 - val_loss: 2.9816\n",
            "Epoch 30/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 3s/step - accuracy: 0.9899 - loss: 0.0219 - val_accuracy: 0.7420 - val_loss: 2.8466\n",
            "Epoch 31/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 3s/step - accuracy: 0.9872 - loss: 0.0249 - val_accuracy: 0.7160 - val_loss: 3.5101\n",
            "Epoch 32/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 3s/step - accuracy: 0.9895 - loss: 0.0241 - val_accuracy: 0.7360 - val_loss: 3.1853\n",
            "Epoch 33/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 3s/step - accuracy: 0.9882 - loss: 0.0282 - val_accuracy: 0.7270 - val_loss: 2.5246\n",
            "Epoch 34/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 3s/step - accuracy: 0.9795 - loss: 0.0493 - val_accuracy: 0.7370 - val_loss: 2.6754\n",
            "Epoch 35/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 3s/step - accuracy: 0.9881 - loss: 0.0310 - val_accuracy: 0.7330 - val_loss: 2.6632\n",
            "Epoch 36/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 3s/step - accuracy: 0.9889 - loss: 0.0228 - val_accuracy: 0.7310 - val_loss: 3.2285\n",
            "Epoch 37/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 3s/step - accuracy: 0.9917 - loss: 0.0175 - val_accuracy: 0.7440 - val_loss: 3.3974\n",
            "Epoch 38/200\n",
            "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m639s\u001b[0m 3s/step - accuracy: 0.9897 - loss: 0.0189 - val_accuracy: 0.7400 - val_loss: 3.6858\n",
            "Epoch 39/200\n",
            "\u001b[1m  7/219\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:39\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0035"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install tensorflow scikit-learn pandas matplotlib -q\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/gdrive/MyDrive/datamining/clinical_notes.csv')  # path\n",
        "\n",
        "\n",
        "\n",
        "# Data Preprocessing\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Tokenization\n",
        "MAX_WORDS = 5000\n",
        "MAX_SEQ_LENGTH = 500\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(data['note'])\n",
        "sequences = tokenizer.texts_to_sequences(data['note'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH, padding='post')\n",
        "\n",
        "\n",
        "# Encode labels\n",
        "label_map = {'yes': 1, 'no': 0}\n",
        "data['glaucoma'] = data['glaucoma'].map(label_map)\n",
        "\n",
        "# Split data based on 'use' column\n",
        "train_indices = data['use'] == 'training'\n",
        "validation_indices = data['use'] == 'validation'\n",
        "test_indices = data['use'] == 'test'\n",
        "\n",
        "\n",
        "\n",
        "X_train, y_train = padded_sequences[train_indices], data['glaucoma'].values[train_indices]\n",
        "X_val, y_val = padded_sequences[validation_indices], data['glaucoma'].values[validation_indices]\n",
        "X_test, y_test = padded_sequences[test_indices], data['glaucoma'].values[test_indices]\n",
        "\n",
        "race_test = data['race'].values[test_indices]  # For racial race evaluation\n",
        "\n",
        "\n",
        "# 4. Define Models\n",
        "def build_lstm_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(MAX_WORDS, 128, input_length=MAX_SEQ_LENGTH),\n",
        "        tf.keras.layers.LSTM(64, return_sequences=False),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(MAX_WORDS, 128, input_length=MAX_SEQ_LENGTH),\n",
        "        tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
        "        tf.keras.layers.GlobalMaxPooling1D(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_transformer_model():\n",
        "    input_layer = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,))\n",
        "    embedding = tf.keras.layers.Embedding(MAX_WORDS, 128)(input_layer)\n",
        "    transformer_block = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=4, key_dim=128, dropout=0.1\n",
        "    )(embedding, embedding)\n",
        "    flatten = tf.keras.layers.GlobalAveragePooling1D()(transformer_block)\n",
        "    dense = tf.keras.layers.Dense(64, activation='relu')(flatten)\n",
        "    output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# 5. Training and Evaluation\n",
        "models = {\n",
        "    'LSTM': build_lstm_model(),\n",
        "    '1D CNN': build_cnn_model(),\n",
        "    'Transformer': build_transformer_model()\n",
        "}\n",
        "\n",
        "history = {}\n",
        "aucs = {}\n",
        "race_aucs = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training {model_name}...\")\n",
        "    history[model_name] = model.fit(\n",
        "        X_train, y_train, validation_data=(X_val, y_val),\n",
        "        epochs=120, batch_size=32, verbose=1\n",
        "    )\n",
        "\n",
        "    # Compute Overall AUC\n",
        "    y_pred = model.predict(X_test).ravel()\n",
        "    aucs[model_name] = roc_auc_score(y_test, y_pred)\n",
        "    print(f\"Overall AUC for {model_name}: {aucs[model_name]}\")\n",
        "\n",
        "    # Compute AUC per racial race\n",
        "    race_aucs[model_name] = {}\n",
        "    for race in ['asian', 'black', 'white']:\n",
        "        race_idx = np.where(race_test == race)\n",
        "        race_auc = roc_auc_score(y_test[race_idx], y_pred[race_idx])\n",
        "        race_aucs[model_name][race] = race_auc\n",
        "        print(f\"  {race} AUC for {model_name}: {race_auc}\")\n",
        "\n",
        "# 6. Visualization\n",
        "for model_name, hist in history.items():\n",
        "    plt.plot(hist.history['val_loss'], label=f'{model_name} Loss')\n",
        "plt.legend()\n",
        "plt.title('Validation Loss Comparison')\n",
        "plt.show()\n",
        "\n",
        "# 7. Summarize Results\n",
        "print(\"Overall AUC Scores:\", aucs)\n",
        "print(\"Race AUC Scores:\", race_aucs)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}