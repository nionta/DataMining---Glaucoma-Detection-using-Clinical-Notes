{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVQtgkaQd35i"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install tensorflow scikit-learn pandas matplotlib -q\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/gdrive/MyDrive/datamining/clinical_notes.csv')  # path\n",
        "\n",
        "\n",
        "\n",
        "# Data Preprocessing\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Tokenization\n",
        "MAX_WORDS = 5000\n",
        "MAX_SEQ_LENGTH = 500\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(data['note'])\n",
        "sequences = tokenizer.texts_to_sequences(data['note'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH, padding='post')\n",
        "\n",
        "\n",
        "# Encode labels\n",
        "label_map = {'yes': 1, 'no': 0}\n",
        "data['glaucoma'] = data['glaucoma'].map(label_map)\n",
        "\n",
        "# Split data based on 'use' column\n",
        "train_indices = data['use'] == 'training'\n",
        "validation_indices = data['use'] == 'validation'\n",
        "test_indices = data['use'] == 'test'\n",
        "\n",
        "\n",
        "\n",
        "X_train, y_train = padded_sequences[train_indices], data['glaucoma'].values[train_indices]\n",
        "X_val, y_val = padded_sequences[validation_indices], data['glaucoma'].values[validation_indices]\n",
        "X_test, y_test = padded_sequences[test_indices], data['glaucoma'].values[test_indices]\n",
        "\n",
        "race_test = data['race'].values[test_indices]  # For racial race evaluation\n",
        "\n",
        "\n",
        "# 4. Define Models\n",
        "def build_lstm_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(MAX_WORDS, 128, input_length=MAX_SEQ_LENGTH),\n",
        "        tf.keras.layers.LSTM(64, return_sequences=False),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(MAX_WORDS, 128, input_length=MAX_SEQ_LENGTH),\n",
        "        tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
        "        tf.keras.layers.GlobalMaxPooling1D(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_transformer_model():\n",
        "    input_layer = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,))\n",
        "    embedding = tf.keras.layers.Embedding(MAX_WORDS, 128)(input_layer)\n",
        "    transformer_block = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=4, key_dim=128, dropout=0.1\n",
        "    )(embedding, embedding)\n",
        "    flatten = tf.keras.layers.GlobalAveragePooling1D()(transformer_block)\n",
        "    dense = tf.keras.layers.Dense(64, activation='relu')(flatten)\n",
        "    output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# 5. Training and Evaluation\n",
        "models = {\n",
        "    'LSTM': build_lstm_model(),\n",
        "    '1D CNN': build_cnn_model(),\n",
        "    'Transformer': build_transformer_model()\n",
        "}\n",
        "\n",
        "history = {}\n",
        "aucs = {}\n",
        "race_aucs = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training {model_name}...\")\n",
        "    history[model_name] = model.fit(\n",
        "        X_train, y_train, validation_data=(X_val, y_val),\n",
        "        epochs=120, batch_size=32, verbose=1\n",
        "    )\n",
        "\n",
        "    # Compute Overall AUC\n",
        "    y_pred = model.predict(X_test).ravel()\n",
        "    aucs[model_name] = roc_auc_score(y_test, y_pred)\n",
        "    print(f\"Overall AUC for {model_name}: {aucs[model_name]}\")\n",
        "\n",
        "    # Compute AUC per racial race\n",
        "    race_aucs[model_name] = {}\n",
        "    for race in ['asian', 'black', 'white']:\n",
        "        race_idx = np.where(race_test == race)\n",
        "        race_auc = roc_auc_score(y_test[race_idx], y_pred[race_idx])\n",
        "        race_aucs[model_name][race] = race_auc\n",
        "        print(f\"  {race} AUC for {model_name}: {race_auc}\")\n",
        "\n",
        "# 6. Visualization\n",
        "for model_name, hist in history.items():\n",
        "    plt.plot(hist.history['val_loss'], label=f'{model_name} Loss')\n",
        "plt.legend()\n",
        "plt.title('Validation Loss Comparison')\n",
        "plt.show()\n",
        "\n",
        "# 7. Summarize Results\n",
        "print(\"Overall AUC Scores:\", aucs)\n",
        "print(\"Race AUC Scores:\", race_aucs)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}